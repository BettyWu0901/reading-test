import streamlit as st
import pandas as pd
import datetime
import os
import json
import google.generativeai as genai

# ==========================================
# 1. è¨­å®š AI (è®€å–ä¿éšªç®±è£¡çš„é‘°åŒ™)
# ==========================================
# å˜—è©¦å¾ Streamlit Secrets è®€å–é‡‘é‘°
try:
    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        ai_available = True
    else:
        ai_available = False
except FileNotFoundError:
    ai_available = False

# ==========================================
# 2. AI æ ¸å¿ƒåŠŸèƒ½å€
# ==========================================

def call_ai_generate_quiz(level, text_content):
    """
    å‘¼å« Google Gemini é–±è®€æ–‡ç« ä¸¦å‡ºé¡Œ
    """
    if not ai_available:
        return get_mock_quiz() # å¦‚æœæ²’é‘°åŒ™ï¼Œå°±ç”¨èˆŠçš„å‡é¡Œç›®é¿å…ç•¶æ©Ÿ

    # ä¾ç…§ç­‰ç´šè¨­å®šå‡ºé¡Œè¦å‰‡
    if level == "A":
        rule = "å‡ºé¡Œè¦å‰‡ï¼šé©åˆä¸€èˆ¬ç¨‹åº¦ã€‚éœ€åŒ…å«ï¼šæå–è¨Šæ¯2é¡Œã€æ¨è«–è¨Šæ¯4é¡Œã€è©®é‡‹æ•´åˆæˆ–æ¯”è¼ƒè©•ä¼°4é¡Œã€‚å•ç­”é¡Œ1é¡Œã€‚"
    elif level == "B":
        rule = "å‡ºé¡Œè¦å‰‡ï¼šé©åˆç²¾ç†Ÿç¨‹åº¦ã€‚éœ€åŒ…å«ï¼šæå–è¨Šæ¯1é¡Œã€æ¨è«–è¨Šæ¯3é¡Œã€è©®é‡‹æ•´åˆæˆ–æ¯”è¼ƒè©•ä¼°6é¡Œã€‚å•ç­”é¡Œ2é¡Œã€‚"
    else: # Level C
        rule = "å‡ºé¡Œè¦å‰‡ï¼šé©åˆæ·±åˆ»é«”æœƒç¨‹åº¦ã€‚éœ€åŒ…å«ï¼šæ¨è«–è¨Šæ¯3é¡Œã€è©®é‡‹æ•´åˆæˆ–æ¯”è¼ƒè©•ä¼°7é¡Œã€‚å•ç­”é¡Œ3é¡Œã€‚"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„åœ‹å°é–±è®€ç´ é¤Šå‡ºé¡Œè€å¸«ã€‚è«‹é–±è®€ä»¥ä¸‹æ–‡ç« ï¼Œä¸¦ä¾ç…§è¦å‰‡ç”¢å‡ºä¸€ä»½æ¸¬é©—å·ã€‚
    
    ã€æ–‡ç« å…§å®¹ã€‘ï¼š
    {text_content[:15000]} 
    (è‹¥æ–‡ç« éé•·è«‹åªè®€å‰15000å­—)

    ã€{rule}ã€‘
    
    ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘ï¼š
    è«‹ç›´æ¥å›å‚³ä¸€å€‹åˆæ³•çš„ JSON æ ¼å¼ï¼Œä¸è¦æœ‰ä»»ä½• Markdown æ¨™è¨˜ï¼ˆä¸è¦å¯« ```jsonï¼‰ã€‚
    JSON çµæ§‹å¿…é ˆå¦‚ä¸‹ï¼š
    {{
        "qa_questions": [
            {{"id": 1, "question": "å•ç­”é¡Œé¡Œç›®...", "score": 20}},
            ...
        ],
        "mc_questions": [
            {{"id": 1, "type": "æå–è¨Šæ¯", "question": "é¸æ“‡é¡Œé¡Œç›®...", "options": ["1. é¸é …A", "2. é¸é …B", "3. é¸é …C", "4. é¸é …D"], "answer": "æ­£ç¢ºé¸é …çš„ç·¨è™Ÿ(ä¾‹å¦‚ 2)"}},
            ...
        ]
    }}
    è«‹ç¢ºä¿é¸æ“‡é¡Œæœ‰ 4 å€‹é¸é …ã€‚
    """

    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        # æ¸…ç†å›æ‡‰ï¼Œç¢ºä¿æ˜¯ç´” JSON
        clean_text = response.text.replace("```json", "").replace("```", "").strip()
        quiz_json = json.loads(clean_text)
        return quiz_json
    except Exception as e:
        st.error(f"AI å‡ºé¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œæ”¹ç‚ºä½¿ç”¨å‚™ç”¨é¡Œåº«ã€‚éŒ¯èª¤åŸå› ï¼š{e}")
        return get_mock_quiz()

def call_ai_grade_qa(question, student_answer, story_text):
    """
    å‘¼å« AI è©•åˆ†å•ç­”é¡Œ
    """
    if not ai_available:
        return 15, "ï¼ˆæ¨¡æ“¬è©•åˆ†ï¼‰å¯«å¾—ä¸éŒ¯ï¼ä½†è«‹è¨˜å¾—æˆ‘å€‘ç¾åœ¨é‚„æ²’æ¥ä¸ŠçœŸ AI å–”ã€‚"

    prompt = f"""
    ä½ æ˜¯åœ‹å°é–±è®€è€å¸«ã€‚è«‹é‡å°å­¸ç”Ÿçš„å›ç­”é€²è¡Œè©•åˆ†ã€‚
    
    é¡Œç›®ï¼š{question}
    å­¸ç”Ÿå›ç­”ï¼š{student_answer}
    æ–‡ç« èƒŒæ™¯ï¼šè«‹ä¾æ“šå‰›æ‰é–±è®€çš„æ•…äº‹å…§å®¹ã€‚
    
    ã€è©•åˆ†æ¨™æº– (æ»¿åˆ†20åˆ†)ã€‘ï¼š
    1. äº†è§£é¡Œæ„ (0-6åˆ†)
    2. å…§å®¹æ­£ç¢ºåˆç† (0-6åˆ†)
    3. ç¨ç‰¹è¦‹è§£èˆ‡å‰µæ„ (0-8åˆ†)
    
    è«‹å›å‚³æ ¼å¼ï¼š
    åˆ†æ•¸|è©•èª
    (ä¾‹å¦‚ï¼š16|ä½ èƒ½ç†è§£æ•…äº‹ï¼Œä½†åœ¨å‰µæ„éƒ¨åˆ†å¯ä»¥å†å¤šä¸€é»æƒ³æ³•ã€‚)
    """
    
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        text = response.text.strip()
        if "|" in text:
            score_str, feedback = text.split("|", 1)
            return int(float(score_str)), feedback
        else:
            return 10, text # æ ¼å¼è·‘æ‰æ™‚çš„é è¨­è™•ç†
    except:
        return 10, "AI è©•åˆ†é€£ç·šå¿™ç¢Œä¸­ï¼Œçµ¦äºˆåŸºæœ¬åˆ†ã€‚"

def call_ai_final_comment(total_score, qa_feedback, story_text):
    if not ai_available:
        return "æ¨¡æ“¬ç¸½è©•ï¼šæ­å–œå®Œæˆæ¸¬é©—ï¼"
        
    prompt = f"""
    å­¸ç”Ÿå®Œæˆäº†é–±è®€æ¸¬é©—ï¼Œç¸½åˆ†æ˜¯ {total_score} åˆ†ã€‚
    è«‹çµ¦å­¸ç”Ÿä¸€æ®µ 50 å­—ä»¥å…§çš„ç¹é«”ä¸­æ–‡é¼“å‹µè©•èªï¼Œèªæ°£è¦æº«æŸ”ã€æ­£å‘ï¼Œåƒä¸€ä½è¦ªåˆ‡çš„è€å¸«ã€‚
    """
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        return response.text.strip()
    except:
        return "æ¸¬é©—å®Œæˆï¼ç¹¼çºŒåŠ æ²¹ï¼"

def get_mock_quiz():
    """å‚™ç”¨é¡Œåº« (ç•¶ AI é€£ç·šå¤±æ•—æ™‚ä½¿ç”¨)"""
    return {
        "qa_questions": [{"id": 1, "question": "ç‚ºä»€éº¼çœŸç”±ç¾æœƒé•·å‡ºé­šé±—ï¼Ÿ(å‚™ç”¨é¡Œåº«)", "score": 20}],
        "mc_questions": [
            {"id": 1, "type": "æå–è¨Šæ¯", "question": "çœŸç”±ç¾ç”¨ä»€éº¼æ›åˆ°äº†ç¾äººé­šè»Ÿç³–ï¼Ÿ", "options": ["1. 100å…ƒ", "2. æ˜­å’Œ42å¹´çš„10å…ƒ", "3. é‡¦å­", "4. å¯¶çŸ³"], "answer": "2"},
            {"id": 2, "type": "æ¨è«–è¨Šæ¯", "question": "éŒ¢å¤©å ‚æœ‰ä»€éº¼ç‰¹å¾µï¼Ÿ", "options": ["1. åœ¨å¤§é¦¬è·¯æ—", "2. åªæœ‰å¹¸é‹çš„äººèƒ½æ‰¾åˆ°", "3. è³£æ–‡å…·", "4. è€é—†æ˜¯ç”·ç”Ÿ"], "answer": "2"}
        ]
    }

# ==========================================
# 3. ç³»çµ±èˆ‡ä»‹é¢ (é€™è£¡å¤§éƒ¨åˆ†ä¸ç”¨å‹•)
# ==========================================

FILE_NAME = "reading_records.csv"

def save_to_csv(data):
    df_new = pd.DataFrame([data])
    if not os.path.exists(FILE_NAME):
        df_new.to_csv(FILE_NAME, index=False, encoding='utf-8-sig')
    else:
        df_new.to_csv(FILE_NAME, mode='a', header=False, index=False, encoding='utf-8-sig')

def load_story():
    if os.path.exists("story.txt"):
        with open("story.txt", "r", encoding="utf-8") as f:
            return f.read()
    return "æ‰¾ä¸åˆ° story.txtï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚"

st.set_page_config(page_title="ç¥å¥‡æŸ‘ä»”åº— - AI é–±è®€èªè­‰", page_icon="ğŸ¤–")
st.title("ğŸ¤– ç¥å¥‡æŸ‘ä»”åº— - AI é–±è®€æŒ‘æˆ°")

if not ai_available:
    st.warning("âš ï¸ å°šæœªåµæ¸¬åˆ° API Keyï¼Œç³»çµ±ç›®å‰ç‚ºã€Œæ¨¡æ“¬æ¨¡å¼ã€ã€‚è«‹è€å¸«åˆ° Streamlit Secrets è¨­å®š GEMINI_API_KEYã€‚")

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("1. å­¸ç”Ÿè³‡æ–™ç™»å…¥")
    student_class = st.text_input("ç­ç´š", placeholder="ä¾‹å¦‚ï¼š501")
    seat_num = st.text_input("åº§è™Ÿ", placeholder="ä¾‹å¦‚ï¼š05")
    student_name = st.text_input("å§“å", placeholder="ç‹å°æ˜")
    st.markdown("---")
    st.header("2. è€å¸«å°ˆå€")
    password = st.text_input("è¼¸å…¥å¯†ç¢¼ä¸‹è¼‰å ±è¡¨", type="password")
    if password == "1234":
        if os.path.exists(FILE_NAME):
            with open(FILE_NAME, "rb") as f:
                st.download_button("ä¸‹è¼‰ Excel (CSV)", f, file_name="student_scores.csv")
        else:
            st.info("ç›®å‰é‚„æ²’æœ‰è³‡æ–™å–”ï¼")

# --- åˆå§‹åŒ– ---
if 'step' not in st.session_state: st.session_state.step = 'login'
if 'quiz_data' not in st.session_state: st.session_state.quiz_data = {}
if 'current_q_index' not in st.session_state: st.session_state.current_q_index = 0
if 'answers' not in st.session_state: st.session_state.answers = []
if 'history' not in st.session_state: st.session_state.history = []

# --- æµç¨‹æ§åˆ¶ ---
if not (student_class and seat_num and student_name):
    st.warning("ğŸ‘ˆ è«‹å…ˆè¼¸å…¥ç­ç´šã€åº§è™Ÿã€å§“å")
    st.stop()

if st.session_state.step == 'login':
    st.subheader(f"ğŸ‘‹ {student_name} ä½ å¥½ï¼")
    st.write("è«‹é¸æ“‡æŒ‘æˆ°ç­‰ç´šï¼š")
    c1, c2, c3 = st.columns(3)
    if c1.button("ç­‰ç´š A (ä¸€èˆ¬)"): 
        st.session_state.level = "A"
        st.session_state.step = 'confirm_level'
        st.rerun()
    if c2.button("ç­‰ç´š B (ç²¾ç†Ÿ)"): 
        st.session_state.level = "B"
        st.session_state.step = 'confirm_level'
        st.rerun()
    if c3.button("ç­‰ç´š C (æ·±åˆ»)"): 
        st.session_state.level = "C"
        st.session_state.step = 'confirm_level'
        st.rerun()

elif st.session_state.step == 'confirm_level':
    st.info(f"ä½ é¸æ“‡äº†ç­‰ç´š {st.session_state.level}ï¼ŒAI è€å¸«æ­£åœ¨è®€æ›¸å‡ºé¡Œï¼Œè«‹ç¨ç­‰...")
    if st.button("é–‹å§‹æ¸¬é©—"):
        with st.spinner("AI æ­£åœ¨é–±è®€ã€Šç¥å¥‡æŸ‘ä»”åº—ã€‹ä¸¦ç”Ÿæˆé¡Œç›®ä¸­... (ç´„éœ€ 10-20 ç§’)"):
            story_text = load_story()
            quiz = call_ai_generate_quiz(st.session_state.level, story_text)
            st.session_state.quiz_data = quiz
            st.session_state.all_questions = []
            
            # æ•´åˆé¡Œç›®
            if "qa_questions" in quiz:
                for q in quiz['qa_questions']: 
                    st.session_state.all_questions.append({'type': 'QA', 'data': q})
            if "mc_questions" in quiz:
                for q in quiz['mc_questions']: 
                    st.session_state.all_questions.append({'type': 'MC', 'data': q})
            
            # é–‹å ´ç™½
            st.session_state.history = []
            st.session_state.history.append({"role": "bot", "content": f"ä½ å¥½ï¼æˆ‘æ˜¯ AI é–±è®€è€å¸«ã€‚æˆ‘å‰›å‰›è®€å®Œäº†é€™æœ¬æ›¸ï¼Œç¾åœ¨è¦ä¾†è€ƒè€ƒä½ ã€‚\n\næˆ‘å€‘ä¸€é¡Œä¸€é¡Œä¾†ï¼Œæº–å‚™å¥½äº†å—ï¼Ÿ"})
            
            # ç¬¬ä¸€é¡Œ
            if len(st.session_state.all_questions) > 0:
                first_q = st.session_state.all_questions[0]
                if first_q['type'] == 'QA':
                    st.session_state.history.append({"role": "bot", "content": f"ã€å•ç­”é¡Œã€‘ {first_q['data']['question']}"})
                else:
                    opts = "\n".join(first_q['data']['options'])
                    st.session_state.history.append({"role": "bot", "content": f"ã€é¸æ“‡é¡Œã€‘ {first_q['data']['question']}\n{opts}"})
                st.session_state.step = 'testing'
                st.rerun()
            else:
                st.error("AI å‡ºé¡Œå¤±æ•—ï¼Œè«‹é‡æ–°æ•´ç†è©¦è©¦çœ‹ã€‚")

elif st.session_state.step == 'testing':
    for msg in st.session_state.history:
        with st.chat_message(msg["role"]): st.write(msg["content"])
    
    current_idx = st.session_state.current_q_index
    total_q = len(st.session_state.all_questions)
    
    if current_idx < total_q:
        q_data = st.session_state.all_questions[current_idx]
        if q_data['type'] == 'QA':
            user_input = st.chat_input("è«‹è¼¸å…¥å›ç­”...")
        else:
            user_input = st.chat_input("è«‹è¼¸å…¥é¸é …ç·¨è™Ÿ (ä¾‹å¦‚: 2)")

        if user_input:
            with st.chat_message("user"): st.write(user_input)
            st.session_state.history.append({"role": "user", "content": user_input})
            st.session_state.answers.append({
                "type": q_data['type'], 
                "user_response": user_input, 
                "question_data": q_data['data']
            })
            
            next_idx = current_idx + 1
            st.session_state.current_q_index = next_idx
            
            if next_idx < total_q:
                next_q = st.session_state.all_questions[next_idx]
                if next_q['type'] == 'QA':
                    content = f"ã€å•ç­”é¡Œã€‘ {next_q['data']['question']}"
                else:
                    opts = "\n".join(next_q['data']['options'])
                    content = f"ã€é¸æ“‡é¡Œã€‘ {next_q['data']['question']}\n{opts}"
                
                bot_msg = f"æ”¶åˆ°ï¼\n\nä¸‹ä¸€é¡Œï¼š\n{content}"
                st.session_state.history.append({"role": "bot", "content": bot_msg})
                st.rerun()
            else:
                st.session_state.step = 'calculating'
                st.rerun()

elif st.session_state.step == 'calculating':
    with st.spinner("AI è€å¸«æ­£åœ¨æ”¹è€ƒå·...è«‹ç¨ç­‰..."):
        story_text = load_story()
        total = 0
        mc_score = 0
        qa_score = 0
        
        for ans in st.session_state.answers:
            if ans['type'] == 'MC':
                # ç°¡å–®æ¯”å°ç¬¬ä¸€å€‹å­—å…ƒ
                user_ans = str(ans['user_response']).strip()[0]
                correct = str(ans['question_data']['answer']).strip()[0]
                
                # é…åˆ†é‚è¼¯
                pts = 8 # A
                if st.session_state.level == "B": pts = 6
                elif st.session_state.level == "C": pts = 4
                
                if user_ans == correct:
                    total += pts
                    mc_score += pts
            elif ans['type'] == 'QA':
                score, fb = call_ai_grade_qa(ans['question_data']['question'], ans['user_response'], story_text)
                total += score
                qa_score += score
        
        final_cmt = call_ai_final_comment(total, "", story_text)
        
        rec = {
            "ç­ç´š": student_class,
            "åº§è™Ÿ": seat_num,
            "å§“å": student_name,
            "æ—¥æœŸ": datetime.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "ç­‰ç´š": st.session_state.level,
            "é¸æ“‡é¡Œå¾—åˆ†": mc_score,
            "å•ç­”é¡Œå¾—åˆ†": qa_score,
            "ç¸½åˆ†": total,
            "æ©Ÿå™¨äººç¸½è©•": final_cmt
        }
        save_to_csv(rec)
        st.session_state.final_result = rec
        st.session_state.step = 'finished'
        st.rerun()

elif st.session_state.step == 'finished':
    res = st.session_state.final_result
    st.balloons()
    st.markdown(f"### ğŸ“„ æˆç¸¾å–®\n**å§“å**ï¼š{res['å§“å']}\n**ç¸½åˆ†**ï¼š{res['ç¸½åˆ†']} åˆ†")
    if res['ç¸½åˆ†'] >= 60: st.success("é€šéèªè­‰ï¼ ğŸ‰")
    else: st.error("æœªé€šéï¼Œå†åŠ æ²¹ï¼ ğŸ’ª")
    st.info(f"**AI è€å¸«è©•èª**ï¼š\n{res['æ©Ÿå™¨äººç¸½è©•']}")
    
    if st.button("é‡æ–°é–‹å§‹"):
        for k in list(st.session_state.keys()): del st.session_state[k]
        st.rerun()
