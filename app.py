import streamlit as st
import pandas as pd
import datetime
import os
import json

# ==========================================
# 1. AI è¨­å®šèˆ‡è¨ºæ–·å€
# ==========================================
ai_status_msg = ""
ai_available = False

try:
    # æ¸¬è©¦ 1: æª¢æŸ¥æ˜¯å¦èƒ½è¼‰å…¥ Google å·¥å…·
    import google.generativeai as genai
    
    # æ¸¬è©¦ 2: æª¢æŸ¥ä¿éšªç®±æœ‰æ²’æœ‰é‘°åŒ™
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        ai_available = True
        ai_status_msg = "âœ… AI é€£ç·šæˆåŠŸï¼(é©…å‹•èˆ‡é‡‘é‘°çš†æ­£å¸¸)"
    else:
        ai_available = False
        ai_status_msg = "âŒ å¤±æ•—ï¼šSecrets è£¡æ‰¾ä¸åˆ° 'GEMINI_API_KEY'ã€‚è«‹æª¢æŸ¥åç¨±æ˜¯å¦å®Œå…¨æ­£ç¢º (å…¨å¤§å¯«)ã€‚"

except ImportError:
    ai_available = False
    ai_status_msg = "âŒ å¤±æ•—ï¼šæ‰¾ä¸åˆ° 'google-generativeai' å·¥å…·ã€‚è«‹ç¢ºèª requirements.txt æœ‰å„²å­˜æˆåŠŸã€‚"
except Exception as e:
    ai_available = False
    ai_status_msg = f"âŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {str(e)}"

# ==========================================
# 2. AI æ ¸å¿ƒåŠŸèƒ½å€
# ==========================================

# --- å®‰å…¨è¨­å®šï¼šé˜²æ­¢ AI å› ç‚ºæ•…äº‹å…§å®¹(é¬¼æ€ª/ææ€–)è€Œæ‹’çµ•å›ç­” ---
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

def get_mock_quiz():
    """å‚™ç”¨é¡Œåº« (ç•¶ AI é€£ç·šå¤±æ•—æˆ–å ±éŒ¯æ™‚ä½¿ç”¨)"""
    return {
        "qa_questions": [{"id": 1, "question": "ç‚ºä»€éº¼çœŸç”±ç¾æœƒé•·å‡ºé­šé±—ï¼Ÿ(é€™æ˜¯å‚™ç”¨é¡Œåº«ï¼Œä»£è¡¨ AI ç™¼ç”ŸéŒ¯èª¤)", "score": 20}],
        "mc_questions": [
            {"id": 1, "type": "æå–è¨Šæ¯", "question": "çœŸç”±ç¾ç”¨ä»€éº¼æ›åˆ°äº†ç¾äººé­šè»Ÿç³–ï¼Ÿ", "options": ["1. 100å…ƒ", "2. æ˜­å’Œ42å¹´çš„10å…ƒ", "3. é‡¦å­", "4. å¯¶çŸ³"], "answer": "2"},
            {"id": 2, "type": "æ¨è«–è¨Šæ¯", "question": "éŒ¢å¤©å ‚æœ‰ä»€éº¼ç‰¹å¾µï¼Ÿ", "options": ["1. åœ¨å¤§é¦¬è·¯æ—", "2. åªæœ‰å¹¸é‹çš„äººèƒ½æ‰¾åˆ°", "3. è³£æ–‡å…·", "4. è€é—†æ˜¯ç”·ç”Ÿ"], "answer": "2"}
        ]
    }

def call_ai_generate_quiz(level, text_content):
    if not ai_available:
        return get_mock_quiz()

    # ä¾ç…§ç­‰ç´šè¨­å®šå‡ºé¡Œè¦å‰‡
    if level == "A":
        rule = "å‡ºé¡Œè¦å‰‡ï¼šé©åˆä¸€èˆ¬ç¨‹åº¦ã€‚éœ€åŒ…å«ï¼šæå–è¨Šæ¯2é¡Œã€æ¨è«–è¨Šæ¯4é¡Œã€è©®é‡‹æ•´åˆæˆ–æ¯”è¼ƒè©•ä¼°4é¡Œã€‚å•ç­”é¡Œ1é¡Œã€‚"
    elif level == "B":
        rule = "å‡ºé¡Œè¦å‰‡ï¼šé©åˆç²¾ç†Ÿç¨‹åº¦ã€‚éœ€åŒ…å«ï¼šæå–è¨Šæ¯1é¡Œã€æ¨è«–è¨Šæ¯3é¡Œã€è©®é‡‹æ•´åˆæˆ–æ¯”è¼ƒè©•ä¼°6é¡Œã€‚å•ç­”é¡Œ2é¡Œã€‚"
    else: # Level C
        rule = "å‡ºé¡Œè¦å‰‡ï¼šé©åˆæ·±åˆ»é«”æœƒç¨‹åº¦ã€‚éœ€åŒ…å«ï¼šæ¨è«–è¨Šæ¯3é¡Œã€è©®é‡‹æ•´åˆæˆ–æ¯”è¼ƒè©•ä¼°7é¡Œã€‚å•ç­”é¡Œ3é¡Œã€‚"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„åœ‹å°é–±è®€ç´ é¤Šå‡ºé¡Œè€å¸«ã€‚è«‹é–±è®€ä»¥ä¸‹æ–‡ç« ï¼Œä¸¦ä¾ç…§è¦å‰‡ç”¢å‡ºä¸€ä»½æ¸¬é©—å·ã€‚
    ã€æ–‡ç« å…§å®¹ã€‘ï¼š{text_content[:30000]} 
    ã€{rule}ã€‘
    ã€æ ¼å¼è¦æ±‚ã€‘ï¼šè«‹å›å‚³ç´” JSON æ ¼å¼ã€‚
    JSON çµæ§‹ç¯„ä¾‹ï¼š
    {{
        "qa_questions": [{{"id": 1, "question": "...", "score": 20}}],
        "mc_questions": [{{"id": 1, "type": "...", "question": "...", "options": ["1. A", "2. B", "3. C", "4. D"], "answer": "2"}}]
    }}
    è«‹ç¢ºä¿é¸æ“‡é¡Œæœ‰ 4 å€‹é¸é …ã€‚
    """
    try:
        # ã€é‡è¦ä¿®æ”¹ã€‘ä½¿ç”¨è¨ºæ–·å‡ºä¾†çš„ gemini-2.5-flash æ¨¡å‹
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt, safety_settings=safety_settings)
        
        # æ¸…ç†å›æ‡‰æ–‡å­—ï¼Œç¢ºä¿æ˜¯ç´” JSON
        clean_text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(clean_text)
    except Exception as e:
        # å°‡è©³ç´°éŒ¯èª¤é¡¯ç¤ºåœ¨å´é‚Šæ¬„ï¼Œæ–¹ä¾¿é™¤éŒ¯
        st.sidebar.error(f"AI å‡ºé¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return get_mock_quiz()

def call_ai_grade_qa(question, student_answer, story_text):
    if not ai_available: return 15, "ï¼ˆæ¨¡æ“¬è©•åˆ†ï¼‰AI æœªé€£ç·šã€‚"
    try:
        # ã€é‡è¦ä¿®æ”¹ã€‘ä½¿ç”¨ gemini-2.5-flash
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(
            f"è«‹è©•åˆ†(æ»¿åˆ†20)ï¼šé¡Œç›®ï¼š{question}ï¼Œå›ç­”ï¼š{student_answer}ã€‚å›å‚³æ ¼å¼ï¼šåˆ†æ•¸|è©•èª",
            safety_settings=safety_settings
        )
        text = response.text.strip()
        if "|" in text:
            s, f = text.split("|", 1)
            return int(float(s)), f
        return 10, text
    except:
        return 10, "AI è©•åˆ†å¿™ç¢Œä¸­ã€‚"

def call_ai_final_comment(total, qa_feedback, story_text):
    if not ai_available: return "æ¨¡æ“¬ç¸½è©•ï¼šå®Œæˆï¼"
    try:
        # ã€é‡è¦ä¿®æ”¹ã€‘ä½¿ç”¨ gemini-2.5-flash
        model = genai.GenerativeModel('gemini-2.5-flash')
        return model.generate_content(f"çµ¦äºˆç¸½åˆ† {total} åˆ†çš„å­¸ç”Ÿä¸€å¥ç¹é«”ä¸­æ–‡é¼“å‹µã€‚", safety_settings=safety_settings).text.strip()
    except:
        return "æ¸¬é©—å®Œæˆï¼ç¹¼çºŒåŠ æ²¹ï¼"

# ==========================================
# 3. ä»‹é¢èˆ‡æµç¨‹
# ==========================================
FILE_NAME = "reading_records.csv"
def save_to_csv(data):
    df_new = pd.DataFrame([data])
    if not os.path.exists(FILE_NAME):
        df_new.to_csv(FILE_NAME, index=False, encoding='utf-8-sig')
    else:
        df_new.to_csv(FILE_NAME, mode='a', header=False, index=False, encoding='utf-8-sig')

def load_story():
    if os.path.exists("story.txt"):
        with open("story.txt", "r", encoding="utf-8") as f: return f.read()
    return "æ‰¾ä¸åˆ° story.txt"

st.set_page_config(page_title="ç¥å¥‡æŸ‘ä»”åº— - AI é–±è®€èªè­‰", page_icon="ğŸ¤–")
st.title("ğŸ¤– ç¥å¥‡æŸ‘ä»”åº— - AI é–±è®€æŒ‘æˆ°")

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ”§ ç³»çµ±ç‹€æ…‹æª¢æŸ¥")
    if ai_available:
        st.success(ai_status_msg)
    else:
        st.error(ai_status_msg)
        
    st.markdown("---")
    st.header("1. å­¸ç”Ÿè³‡æ–™")
    student_class = st.text_input("ç­ç´š")
    seat_num = st.text_input("åº§è™Ÿ")
    student_name = st.text_input("å§“å")
    st.header("2. è€å¸«å°ˆå€")
    if st.text_input("å¯†ç¢¼", type="password") == "1234":
        if os.path.exists(FILE_NAME):
            with open(FILE_NAME, "rb") as f: st.download_button("ä¸‹è¼‰æˆç¸¾å–®", f, "scores.csv")

# --- åˆå§‹åŒ– Session State ---
if 'step' not in st.session_state: st.session_state.step = 'login'
if 'quiz_data' not in st.session_state: st.session_state.quiz_data = {}
if 'current_q_index' not in st.session_state: st.session_state.current_q_index = 0
if 'answers' not in st.session_state: st.session_state.answers = []
if 'history' not in st.session_state: st.session_state.history = []

# --- ä¸»æµç¨‹é‚è¼¯ ---
if not (student_class and seat_num and student_name):
    st.warning("ğŸ‘ˆ è«‹å…ˆè¼¸å…¥ç­ç´šã€åº§è™Ÿã€å§“å")
    st.stop()

if st.session_state.step == 'login':
    st.subheader(f"ğŸ‘‹ {student_name} ä½ å¥½ï¼")
    c1, c2, c3 = st.columns(3)
    if c1.button("A ä¸€èˆ¬"): 
        st.session_state.level = "A"; st.session_state.step = 'confirm'; st.rerun()
    if c2.button("B ç²¾ç†Ÿ"): 
        st.session_state.level = "B"; st.session_state.step = 'confirm'; st.rerun()
    if c3.button("C æ·±åˆ»"): 
        st.session_state.level = "C"; st.session_state.step = 'confirm'; st.rerun()

elif st.session_state.step == 'confirm':
    if st.button("é–‹å§‹æ¸¬é©—"):
        with st.spinner("AI æ­£åœ¨é–±è®€æ•…äº‹ä¸¦å‡ºé¡Œä¸­...(ç´„éœ€ 5-10 ç§’)"):
            story = load_story()
            # å‘¼å« AI å‡ºé¡Œ
            quiz = call_ai_generate_quiz(st.session_state.level, story)
            
            st.session_state.quiz_data = quiz
            st.session_state.all_questions = []
            
            # æ•´ç†é¡Œç›®é †åº
            if "qa_questions" in quiz:
                for q in quiz['qa_questions']: st.session_state.all_questions.append({'type': 'QA', 'data': q})
            if "mc_questions" in quiz:
                for q in quiz['mc_questions']: st.session_state.all_questions.append({'type': 'MC', 'data': q})
            
            # åˆå§‹åŒ–å°è©±ç´€éŒ„
            st.session_state.history = [{"role": "bot", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ AI è€å¸«ï¼Œæ¸¬é©—é–‹å§‹å›‰ï¼"}]
            
            # é¡¯ç¤ºç¬¬ä¸€é¡Œ
            if len(st.session_state.all_questions) > 0:
                q1 = st.session_state.all_questions[0]
                q_text = q1['data']['question']
                if q1['type'] == 'MC': q_text += "\n" + "\n".join(q1['data']['options'])
                st.session_state.history.append({"role": "bot", "content": f"ã€ç¬¬ä¸€é¡Œã€‘{q_text}"})
                st.session_state.step = 'testing'
                st.rerun()
            else:
                st.error("éŒ¯èª¤ï¼šæ²’æœ‰ç”¢ç”Ÿä»»ä½•é¡Œç›®ï¼Œè«‹æª¢æŸ¥å´é‚Šæ¬„çš„éŒ¯èª¤è¨Šæ¯ï¼Œæˆ–æŒ‰é‡æ–°æ•´ç†å†è©¦ä¸€æ¬¡ã€‚")

elif st.session_state.step == 'testing':
    # é¡¯ç¤ºæ­·å²å°è©±
    for msg in st.session_state.history:
        with st.chat_message(msg["role"]): st.write(msg["content"])
    
    idx = st.session_state.current_q_index
    if idx < len(st.session_state.all_questions):
        q = st.session_state.all_questions[idx]
        user_input = st.chat_input("è«‹è¼¸å…¥ç­”æ¡ˆ...")
        if user_input:
            # ç´€éŒ„ä½¿ç”¨è€…å›ç­”
            with st.chat_message("user"): st.write(user_input)
            st.session_state.history.append({"role": "user", "content": user_input})
            st.session_state.answers.append({"type": q['type'], "user_response": user_input, "question_data": q['data']})
            
            # æº–å‚™ä¸‹ä¸€é¡Œ
            next_idx = idx + 1
            st.session_state.current_q_index = next_idx
            if next_idx < len(st.session_state.all_questions):
                nq = st.session_state.all_questions[next_idx]
                nq_text = nq['data']['question']
                if nq['type'] == 'MC': nq_text += "\n" + "\n".join(nq['data']['options'])
                st.session_state.history.append({"role": "bot", "content": f"æ”¶åˆ°ï¼ä¸‹ä¸€é¡Œï¼š\n{nq_text}"})
                st.rerun()
            else:
                # é¡Œç›®åšå®Œäº†ï¼Œé€²å…¥è¨ˆåˆ†
                st.session_state.step = 'calculating'; st.rerun()

elif st.session_state.step == 'calculating':
    with st.spinner("AI è€å¸«æ­£åœ¨æ”¹è€ƒå·..."):
        total = 0; mc = 0; qa = 0
        story = load_story()
        
        for ans in st.session_state.answers:
            if ans['type'] == 'MC':
                # é¸æ“‡é¡Œè©•åˆ† (æª¢æŸ¥ç¬¬ä¸€å€‹å­—å…ƒ)
                if str(ans['user_response'])[0] == str(ans['question_data']['answer'])[0]:
                    pts = 8 if st.session_state.level == "A" else (6 if st.session_state.level == "B" else 4)
                    total += pts; mc += pts
            else:
                # å•ç­”é¡Œå‘¼å« AI è©•åˆ†
                s, f = call_ai_grade_qa(ans['question_data']['question'], ans['user_response'], story)
                total += s; qa += s
        
        cmt = call_ai_final_comment(total, "", story)
        rec = {"ç­ç´š": student_class, "åº§è™Ÿ": seat_num, "å§“å": student_name, "æ—¥æœŸ": datetime.datetime.now().strftime("%Y-%m-%d"), "ç¸½åˆ†": total, "è©•èª": cmt}
        save_to_csv(rec)
        st.session_state.final = rec; st.session_state.step = 'finished'; st.rerun()

elif st.session_state.step == 'finished':
    res = st.session_state.final
    st.balloons()
    st.success(f"ğŸ‰ æ¸¬é©—å®Œæˆï¼ç¸½åˆ†ï¼š{res['ç¸½åˆ†']} åˆ†")
    st.info(f"AI è€å¸«è©•èªï¼š{res['è©•èª']}")
    
    if st.button("ğŸ”„ é‡æ–°é–‹å§‹æ¸¬é©—"):
        for k in list(st.session_state.keys()): del st.session_state[k]
        st.rerun()
