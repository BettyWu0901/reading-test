import streamlit as st
import pandas as pd
import datetime
import os
import json
import time

# ==========================================
# 1. AI è¨­å®šèˆ‡è¨ºæ–·å€
# ==========================================
ai_status_msg = ""
ai_available = False

try:
    import google.generativeai as genai
    if "GEMINI_API_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        ai_available = True
        ai_status_msg = "âœ… AI é€£ç·šæˆåŠŸï¼"
    else:
        ai_available = False
        ai_status_msg = "âŒ å¤±æ•—ï¼šSecrets è£¡æ‰¾ä¸åˆ° 'GEMINI_API_KEY'ã€‚"
except Exception as e:
    ai_available = False
    ai_status_msg = f"âŒ éŒ¯èª¤: {str(e)}"

# ==========================================
# 2. AI æ ¸å¿ƒåŠŸèƒ½å€ (å®Œå…¨ä¾ç…§è¦å‰‡æ–‡ä»¶è¨­å®š)
# ==========================================

safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

def get_mock_quiz():
    return {
        "qa_questions": [{"id": 1, "question": "ç‚ºä»€éº¼çœŸç”±ç¾æœƒé•·å‡ºé­šé±—ï¼Ÿ(å‚™ç”¨é¡Œåº«)", "score": 20}],
        "mc_questions": [
            {"id": 1, "type": "æå–è¨Šæ¯", "question": "çœŸç”±ç¾ç”¨ä»€éº¼æ›åˆ°äº†ç¾äººé­šè»Ÿç³–ï¼Ÿ", "options": ["1. 100å…ƒ", "2. æ˜­å’Œ42å¹´çš„10å…ƒ", "3. é‡¦å­", "4. å¯¶çŸ³", "5. è²æ®¼", "6. å‹‡æ°£"], "answer": "2"}
        ]
    }

def call_ai_generate_quiz(level, text_content):
    if not ai_available: return get_mock_quiz()
    
    # --- ä¾ç…§ã€Œé–±è®€èªè­‰è¦å‰‡.txtã€è¨­å®šåš´æ ¼è¦å‰‡ ---
    if level == "A":
        # Aç´š: å•ç­”1é¡Œï¼Œé¸æ“‡10é¡Œ(æå–2/æ¨è«–4/è©®é‡‹4)
        rule = """
        ã€ç­‰ç´šAè¦å‰‡ã€‘ï¼š
        1. å•ç­”é¡Œï¼šå‡º 1 é¡Œ (æ¯é¡Œ20åˆ†)ã€‚
        2. é¸æ“‡é¡Œï¼šå‡º 10 é¡Œ (æ¯é¡Œ8åˆ†)ã€‚åŒ…å«ï¼šæå–è¨Šæ¯2é¡Œã€æ¨è«–è¨Šæ¯4é¡Œã€è©®é‡‹æ•´åˆ4é¡Œã€‚
        """
    elif level == "B":
        # Bç´š: å•ç­”2é¡Œï¼Œé¸æ“‡10é¡Œ(æå–1/æ¨è«–3/è©®é‡‹6)
        rule = """
        ã€ç­‰ç´šBè¦å‰‡ã€‘ï¼š
        1. å•ç­”é¡Œï¼šå‡º 2 é¡Œ (æ¯é¡Œ20åˆ†)ã€‚
        2. é¸æ“‡é¡Œï¼šå‡º 10 é¡Œ (æ¯é¡Œ6åˆ†)ã€‚åŒ…å«ï¼šæå–è¨Šæ¯1é¡Œã€æ¨è«–è¨Šæ¯3é¡Œã€è©®é‡‹æ•´åˆ6é¡Œã€‚
        """
    else:
        # Cç´š: å•ç­”3é¡Œï¼Œé¸æ“‡10é¡Œ(æ¨è«–3/è©®é‡‹7)
        rule = """
        ã€ç­‰ç´šCè¦å‰‡ã€‘ï¼š
        1. å•ç­”é¡Œï¼šå‡º 3 é¡Œ (æ¯é¡Œ20åˆ†)ã€‚
        2. é¸æ“‡é¡Œï¼šå‡º 10 é¡Œ (æ¯é¡Œ4åˆ†)ã€‚åŒ…å«ï¼šæ¨è«–è¨Šæ¯3é¡Œã€è©®é‡‹æ•´åˆ7é¡Œã€‚
        """

    prompt = f"""
    è«‹ä½ æ ¹æ“šä»¥ä¸‹ã€Šç¥å¥‡æŸ‘ä»”åº—ã€‹çš„æ•…äº‹å…§å®¹ï¼Œç‚ºåœ‹å°å­¸ç”Ÿè¨­è¨ˆä¸€ä»½ã€Œé–±è®€èªè­‰æ¸¬é©—ã€ã€‚
    ã€æ–‡ç« å…§å®¹ã€‘ï¼š{text_content[:30000]} 
    
    ã€é‡è¦å‡ºé¡Œè¦å‰‡ã€‘ï¼š
    {rule}
    3. **é¡Œç›®é †åº**ï¼šJSON ä¸­è«‹åŒ…å« `qa_questions` (å•ç­”) å’Œ `mc_questions` (é¸æ“‡)ã€‚
    4. **é¸æ“‡é¡Œé¸é …**ï¼šæ¯é¡Œå¿…é ˆæœ‰ **6 å€‹é¸é …** (1~6)ï¼Œä¸”è¦æœ‰åˆç†çš„èª˜ç­”æ€§ã€‚
    5. **é¡Œç›®ç„¦é»**ï¼šé‡å°æ•…äº‹åŠ‡æƒ…ã€è§’è‰²è¡Œç‚ºã€å¯“æ„æå•ã€‚åš´ç¦å•æ•™è‚²å­¸æˆ–è©•ä¼°æ–‡ç« çš„å•é¡Œã€‚
    6. **èªè¨€**ï¼šç¹é«”ä¸­æ–‡ã€‚

    ã€æ ¼å¼è¦æ±‚ã€‘ï¼šè«‹å›å‚³ç´” JSON æ ¼å¼ã€‚
    JSON çµæ§‹ç¯„ä¾‹ï¼š
    {{
        "qa_questions": [{{"id": 1, "question": "...", "score": 20}}],
        "mc_questions": [{{"id": 1, "type": "...", "question": "...", "options": ["1. A", "2. B", "3. C", "4. D", "5. E", "6. F"], "answer": "2"}}]
    }}
    """
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt, safety_settings=safety_settings)
        clean_text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(clean_text)
    except:
        return get_mock_quiz()

def call_ai_generate_hint(question, wrong_answer, correct_option_index, options, story_text):
    if not ai_available: return "è«‹å†è®€ä¸€æ¬¡æ•…äº‹å–”ï¼"
    try:
        correct_answer_text = options[int(correct_option_index)-1]
    except:
        correct_answer_text = "æ­£ç¢ºç­”æ¡ˆ"
    
    prompt = f"""
    å­¸ç”Ÿåœ¨é–±è®€æ¸¬é©—ç­”éŒ¯äº†ã€‚è«‹æ‰®æ¼”ç´…å­è€é—†å¨˜çµ¦äºˆæç¤ºã€‚
    ã€é¡Œç›®ã€‘ï¼š{question}
    ã€æ­£ç¢ºç­”æ¡ˆã€‘ï¼š{correct_answer_text}
    ã€åŸå‰‡ã€‘ï¼šä¸ç›´æ¥çµ¦ç­”æ¡ˆï¼Œç”¨å¼•å°çš„æ–¹å¼ã€‚30å­—ä»¥å…§ã€‚
    """
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt, safety_settings=safety_settings)
        return response.text.strip()
    except:
        return "å†ä»”ç´°æƒ³æƒ³æ•…äº‹ç´°ç¯€å–”ï¼"

def call_ai_grade_qa(question, student_answer, story_text):
    if not ai_available: return 10, "AI æœªé€£ç·šã€‚"
    
    prompt = f"""
    è«‹æ‰®æ¼”ã€Šç¥å¥‡æŸ‘ä»”åº—ã€‹ç´…å­è€é—†å¨˜æ‰¹æ”¹å•ç­”é¡Œã€‚
    ã€é¡Œç›®ã€‘ï¼š{question}
    ã€å›ç­”ã€‘ï¼š{student_answer}
    ã€æ¨™æº–ã€‘ï¼šæ»¿åˆ†20åˆ†ã€‚ä¾æ“šï¼š1.äº†è§£é¡Œæ„ 2.å…§å®¹æ­£ç¢ºåˆç† 3.æœ‰ç¨ç‰¹è¦‹è§£ã€‚
    ã€å›é¥‹ã€‘ï¼šè‹¥éŒ¯è«‹å¼•å°ï¼Œè‹¥å°è«‹ç¨±è®šã€‚èªæ°£ç¥ç§˜æº«æš–ã€‚
    æ ¼å¼ï¼šåˆ†æ•¸|è©•èª
    """
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt, safety_settings=safety_settings)
        text = response.text.strip()
        if "|" in text:
            s, f = text.split("|", 1)
            return int(float(s)), f
        return 10, text
    except:
        return 10, "è©•åˆ†ç³»çµ±å¿™ç¢Œä¸­ã€‚"

def call_ai_final_comment(total, level, story_text):
    if not ai_available: return "æ¸¬é©—å®Œæˆï¼"
    # æ ¹æ“šè¦å‰‡æ–‡ä»¶è¨­å®šçš„æ¨™æº–çµ¦è©•èª
    if total >= 80:
        status = "è¡¨ç¾å„ªç§€ï¼å»ºè­°æŒ‘æˆ°æ›´é«˜ç­‰ç´šï¼"
    elif total >= 60:
        status = "é€šéèªè­‰ï¼æ­å–œä½ ï¼"
    else:
        status = "æœªé€šéï¼Œè«‹å†åŠªåŠ›æˆ–é™ç´šå˜—è©¦ã€‚"
        
    prompt = f"""
    å­¸ç”Ÿæ¸¬é©—ç¸½åˆ† {total} åˆ† ({status})ã€‚
    è«‹ç”¨ç´…å­è€é—†å¨˜å£å»çµ¦ä¸€å¥çµèªã€‚
    """
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        return model.generate_content(prompt, safety_settings=safety_settings).text.strip()
    except:
        return f"æ¸¬é©—çµæŸã€‚{status}"

# ==========================================
# 3. ä»‹é¢èˆ‡æµç¨‹
# ==========================================
FILE_NAME = "reading_records.csv"
def save_to_csv(data):
    df_new = pd.DataFrame([data])
    if not os.path.exists(FILE_NAME):
        df_new.to_csv(FILE_NAME, index=False, encoding='utf-8-sig')
    else:
        df_new.to_csv(FILE_NAME, mode='a', header=False, index=False, encoding='utf-8-sig')

def load_story():
    if os.path.exists("story.txt"):
        with open("story.txt", "r", encoding="utf-8") as f: return f.read()
    return "æ‰¾ä¸åˆ° story.txt"

st.set_page_config(page_title="ç¥å¥‡æŸ‘ä»”åº— - AI é–±è®€èªè­‰", page_icon="ğŸ±")
st.title("ğŸ± ç¥å¥‡æŸ‘ä»”åº— - AI é–±è®€æŒ‘æˆ°")

with st.sidebar:
    st.header("ç³»çµ±ç‹€æ…‹")
    if ai_available: st.success(ai_status_msg)
    else: st.error(ai_status_msg)
    st.divider()
    student_class = st.text_input("ç­ç´š")
    seat_num = st.text_input("åº§è™Ÿ")
    student_name = st.text_input("å§“å")
    st.divider()
    if st.text_input("è€å¸«å¯†ç¢¼", type="password") == "1234":
        if os.path.exists(FILE_NAME):
            with open(FILE_NAME, "rb") as f: st.download_button("ä¸‹è¼‰æˆç¸¾å–®", f, "scores.csv")

# --- åˆå§‹åŒ– ---
if 'step' not in st.session_state: st.session_state.step = 'login'
if 'answers' not in st.session_state: st.session_state.answers = []
if 'quiz_data' not in st.session_state: st.session_state.quiz_data = {}
if 'current_q_index' not in st.session_state: st.session_state.current_q_index = 0
if 'all_questions' not in st.session_state: st.session_state.all_questions = []

# --- æµç¨‹ ---
if not (student_class and seat_num and student_name):
    st.warning("è«‹å…ˆåœ¨å·¦å´è¼¸å…¥ç­ç´šã€åº§è™Ÿèˆ‡å§“åã€‚")
    st.stop()

if st.session_state.step == 'login':
    st.subheader(f"ğŸ‘‹ {student_name}ï¼Œæ­¡è¿ä¾†åˆ°éŒ¢å¤©å ‚ï¼")
    st.write("è«‹é¸æ“‡æŒ‘æˆ°é›£åº¦ï¼š")
    c1, c2, c3 = st.columns(3)
    if c1.button("A ä¸€èˆ¬ (åˆéš)"): 
        st.session_state.level = "A"; st.session_state.step = 'confirm'; st.rerun()
    if c2.button("B ç²¾ç†Ÿ (ä¸­éš)"): 
        st.session_state.level = "B"; st.session_state.step = 'confirm'; st.rerun()
    if c3.button("C æ·±åˆ» (é«˜éš)"): 
        st.session_state.level = "C"; st.session_state.step = 'confirm'; st.rerun()

elif st.session_state.step == 'confirm':
    st.markdown(f"### ä½ é¸æ“‡äº†ç­‰ç´šï¼š**{st.session_state.level}**")
    st.write("æº–å‚™å¥½æ¥å—ç´…å­è€é—†å¨˜çš„è€ƒé©—äº†å—ï¼Ÿ")
    
    if st.button("ğŸš€ é€²å…¥éŒ¢å¤©å ‚ (é–‹å§‹æ¸¬é©—)"):
        ani_box = st.empty()
        ani_box.image("https://media.giphy.com/media/JIX9t2j0ZTN9S/giphy.gif", caption="ç´…å­è€é—†å¨˜æ­£æ”¶åˆ°è¨‚å–®", width=300)
        
        with st.status("ğŸ§™â€â™€ï¸ æ­£åœ¨æº–å‚™è€ƒå·...", expanded=True) as status:
            st.write("ğŸ“– é–±è®€æ•…äº‹ä¸­...")
            time.sleep(1)
            st.write("ğŸ˜¼ å¬å–šæ‹›è²¡è²“å‡ºé¡Œ...")
            story = load_story()
            quiz = call_ai_generate_quiz(st.session_state.level, story)
            st.write("âœ¨ å®Œæˆï¼")
            status.update(label="âœ… æº–å‚™å°±ç·’", state="complete", expanded=False)
            time.sleep(0.5)
        
        ani_box.empty()

        # é¡Œç›®è™•ç†ï¼šè¦å‰‡è¦æ±‚å…ˆå‡ºå•ç­”é¡Œï¼Œå†å‡ºé¸æ“‡é¡Œ
        st.session_state.quiz_data = quiz
        st.session_state.all_questions = []
        
        # 1. å…ˆåŠ å…¥å•ç­”é¡Œ (QA)
        if "qa_questions" in quiz:
            for q in quiz['qa_questions']: st.session_state.all_questions.append({'type': 'QA', 'data': q})
        
        # 2. å†åŠ å…¥é¸æ“‡é¡Œ (MC)
        if "mc_questions" in quiz:
            for q in quiz['mc_questions']: st.session_state.all_questions.append({'type': 'MC', 'data': q})
            
        if len(st.session_state.all_questions) > 0:
            st.session_state.step = 'testing'
            st.rerun()
        else:
            st.error("å‡ºé¡Œå¤±æ•—ï¼Œè«‹é‡è©¦ã€‚")

elif st.session_state.step == 'testing':
    total_q = len(st.session_state.all_questions)
    current_idx = st.session_state.current_q_index
    q_data = st.session_state.all_questions[current_idx]
    
    st.progress((current_idx) / total_q)
    st.caption(f"é€²åº¦ï¼š{current_idx + 1} / {total_q}")
    
    # åˆ¤æ–·é¡Œå‹é¡¯ç¤ºæ¨™é¡Œ
    q_type_title = "å•ç­”é¡Œ" if q_data['type'] == 'QA' else "é¸æ“‡é¡Œ"
    st.markdown(f"### ğŸ“ ç¬¬ {current_idx + 1} é¡Œ ({q_type_title})")
    
    question_text = q_data['data']['question']
    st.info(question_text)
    
    if q_data['type'] == 'MC':
        options = q_data['data']['options']
        # è¦å‰‡è¦æ±‚ 6 å€‹é¸é …
        user_ans = st.radio("è«‹é¸æ“‡ç­”æ¡ˆï¼š", options, index=None, key=f"q_{current_idx}")
        
        if st.button("é€å‡ºç­”æ¡ˆ"):
            if user_ans:
                st.session_state.answers.append({
                    "type": "MC", 
                    "question": question_text,
                    "user_response": user_ans, 
                    "data": q_data['data']
                })
                if current_idx + 1 < total_q:
                    st.session_state.current_q_index += 1
                    st.rerun()
                else:
                    st.session_state.step = 'calculating'
                    st.rerun()
            else:
                st.warning("è«‹å…ˆé¸æ“‡ä¸€å€‹ç­”æ¡ˆå–”ï¼")
                
    else: # QA å•ç­”é¡Œ
        user_ans = st.text_area("è«‹è¼¸å…¥ä½ çš„çœ‹æ³•ï¼š", height=150, key=f"q_{current_idx}")
        if st.button("é€å‡ºç­”æ¡ˆ"):
            if user_ans:
                st.session_state.answers.append({
                    "type": "QA", 
                    "question": question_text,
                    "user_response": user_ans, 
                    "data": q_data['data']
                })
                if current_idx + 1 < total_q:
                    st.session_state.current_q_index += 1
                    st.rerun()
                else:
                    st.session_state.step = 'calculating'
                    st.rerun()
            else:
                st.warning("è«‹å¯«ä¸‹ä½ çš„ç­”æ¡ˆå–”ï¼")

elif st.session_state.step == 'calculating':
    ani_box = st.empty()
    ani_box.image("https://media.giphy.com/media/JIX9t2j0ZTN9S/giphy.gif", caption="æ‹›è²¡è²“æ­£åœ¨ä»”ç´°æ‰¹æ”¹...", width=300)
    
    with st.status("ğŸ‘©â€ğŸ« ç´…å­è€å¸«æ­£åœ¨çœ‹ä½ çš„ç­”æ¡ˆ...", expanded=True) as status:
        total = 0
        story = load_story()
        
        # è¨­å®šä¸åŒç­‰ç´šçš„é¸æ“‡é¡Œé…åˆ† (ä¾ç…§è¦å‰‡æ–‡ä»¶)
        mc_score_per_q = 0
        if st.session_state.level == "A": mc_score_per_q = 8
        elif st.session_state.level == "B": mc_score_per_q = 6
        else: mc_score_per_q = 4 # Cç´š

        for ans in st.session_state.answers:
            if ans['type'] == 'MC':
                # é¸æ“‡é¡Œæ‰¹æ”¹
                try:
                    correct_opt_char = str(ans['data']['answer'])[0]
                    user_opt_char = str(ans['user_response'])[0]
                except:
                    correct_opt_char = "X"
                    user_opt_char = "Y"
                
                is_correct = (correct_opt_char == user_opt_char)
                pts = 0
                feedback = ""
                
                if is_correct:
                    pts = mc_score_per_q
                    feedback = "âœ… ç­”å°äº†ï¼ç´…å­è€é—†å¨˜è¦ºå¾—ä½ å¾ˆæœ‰çœ¼å…‰ï¼"
                else:
                    st.write(f"æ­£åœ¨åˆ†æé¸æ“‡é¡ŒéŒ¯èª¤ï¼š{ans['question'][:10]}...")
                    feedback = call_ai_generate_hint(
                        ans['question'], 
                        ans['user_response'], 
                        correct_opt_char, 
                        ans['data']['options'],
                        story
                    )
                    feedback = "ğŸ’¡ " + feedback
                
                total += pts
                ans['score'] = pts
                ans['feedback'] = feedback
                
            else: # QA å•ç­”é¡Œæ‰¹æ”¹
                st.write(f"æ­£åœ¨æ‰¹æ”¹å•ç­”é¡Œï¼š{ans['question'][:10]}...")
                s, f = call_ai_grade_qa(ans['question'], ans['user_response'], story)
                total += s
                ans['score'] = s
                ans['feedback'] = f
        
        status.update(label="æ‰¹æ”¹å®Œæˆï¼", state="complete")
        time.sleep(1)
    
    ani_box.empty()
    
    cmt = call_ai_final_comment(total, st.session_state.level, story)
    
    rec = {
        "ç­ç´š": student_class, 
        "åº§è™Ÿ": seat_num, 
        "å§“å": student_name, 
        "æ—¥æœŸ": datetime.datetime.now().strftime("%Y-%m-%d"), 
        "ç¸½åˆ†": total, 
        "è©•èª": cmt
    }
    save_to_csv(rec)
    st.session_state.final_rec = rec
    st.session_state.step = 'finished'
    st.rerun()

elif st.session_state.step == 'finished':
    rec = st.session_state.final_rec
    st.balloons()
    
    # æ ¹æ“šåˆ†æ•¸é¡¯ç¤ºä¸åŒé¡è‰²
    score_color = "green" if rec['ç¸½åˆ†'] >= 60 else "red"
    st.markdown(f"# ğŸ‰ æŒ‘æˆ°å®Œæˆï¼ç¸½åˆ†ï¼š:{score_color}[{rec['ç¸½åˆ†']} åˆ†]")
    st.info(f"ğŸ‘©â€ğŸ« ç´…å­è€å¸«çš„è©±ï¼š{rec['è©•èª']}")
    
    st.divider()
    
    st.subheader("ğŸ§ è©³ç´°æª¢è¨èˆ‡çœæ€")
    st.write("ä¾†çœ‹çœ‹ç´…å­è€å¸«å°æ¯ä¸€é¡Œçš„å»ºè­°å§ï¼")
    
    for i, ans in enumerate(st.session_state.answers):
        s_color = "green" if ans['score'] > 0 else "red"
        q_type = "(å•ç­”)" if ans['type'] == 'QA' else "(é¸æ“‡)"
        title_text = f"ç¬¬ {i+1} é¡Œ {q_type}ï¼š{ans['question']} (:{s_color}[{ans['score']}åˆ†])"
        
        with st.expander(title_text, expanded=True):
            st.markdown(f"**ä½ çš„å›ç­”ï¼š** {ans['user_response']}")
            st.markdown(f"**ğŸ‘©â€ğŸ« è€å¸«çš„å›é¥‹ï¼š**")
            st.info(ans['feedback'])
            
    if st.button("ğŸ”„ é‡æ–°æŒ‘æˆ°"):
        for k in list(st.session_state.keys()): del st.session_state[k]
        st.rerun()
